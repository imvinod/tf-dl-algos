{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_image = mnist.train.next_batch(1)[0]\n",
    "sample_image = sample_image.reshape([28,28])\n",
    "plt.imshow(sample_image, cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Images coming in are 28 x 28 x 1\n",
    "def discriminator(images, reuse = None):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse = reuse) as scope:\n",
    "        # First convolution and pool layes\n",
    "        # 32 feature maps from 5 x 5 filters\n",
    "        \n",
    "        d_w1 = tf.get_variable('dw1', [5,5,1,32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b1 = tf.get_variable('db1', [32], initializer=tf.constant_initializer(0))\n",
    "        d1 = tf.nn.conv2d(input=images, filter=d_w1, strides = [1,1,1,1], padding='SAME')\n",
    "        # d1 should be 28 x 28 x 32 (op_height= ceil(ip_height/strides) )\n",
    "        d1 = d1 + d_b1\n",
    "        d1 = tf.nn.relu(d1)\n",
    "        d1 = tf.nn.avg_pool(d1, ksize=[1,2,2,1], strides= [1,2,2,1], padding='SAME')\n",
    "        # d1 should be now 14 x 14 x 32 (op_height = ip_height/stride)\n",
    "        \n",
    "        # Second convolution and pool layers\n",
    "        # 64 filters of 5 x 5 x 32\n",
    "        d_w2 = tf.get_variable('dw2', [5,5,32,64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b2 = tf.get_variable('db2', [64], initializer=tf.constant_initializer(0))\n",
    "        d2 = tf.nn.conv2d(input=images, filter=d_w2, strides = [1,1,1,1], padding='SAME')\n",
    "        # d1 should be 14 x 14 x 64 ( op_height= ceil(ip_height/strides) )\n",
    "        d2 = d2 + d_b2\n",
    "        d2 = tf.nn.relu(d2)\n",
    "        d2 = tf.nn.avg_pool(d2, ksize=[1,2,2,1], strides= [1,2,2,1], padding='SAME')\n",
    "        # d1 should be now 7 x 7 X 64 (op_height = ip_height/stride)\n",
    "        \n",
    "        # First fully connected layer\n",
    "        d_w3 = tf.get_variable('dw3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializern(stddev=0.02))\n",
    "        d_b3 = tf.get_variable('db3', [64], initializer=tf.constant_initializer(0))\n",
    "        d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "        d3 = tf.matmul(d3, dw_3)\n",
    "        d3 = d3 + db3\n",
    "        d3 = tf.nn.relu(d3)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "        d4 = tf.matmul(d3, d_w4) + d_b4        \n",
    "        \n",
    "        # d4 contains unscaled value\n",
    "        return d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# z is placeholder, z_dim is 100\n",
    "def generator(z, batch_size, z_dim):\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    # reshape to [-1, 56, 56, 1],  -1 being automatic calculation of batch size, 56x56 is 3136, 1 is channel\n",
    "    g1 = tf.reshape(g1, [-1, 56,56,1])\n",
    "    g1 =tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "    \n",
    "    # Generate 50 filters with dimension 3x3x1\n",
    "    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1,2,2,1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    # Need to understand this better. How resize from 28x28x50 to 56x56 or possibly 56x56x50 not sure\n",
    "    # Looks like resize_images takes height and width and doesn't touch channels (50 in this case) and batch_size\n",
    "    g2 = tf.image.resize_images(g2, [56,56])\n",
    "    \n",
    "    # Generate 25 filters with dimension 3x3x50\n",
    "    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b2', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1,2,2,1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope = 'bn3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "    \n",
    "    # Final convolution with one channel image\n",
    "    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1,2,2,1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    g4 = tf.sigmoid(g4)\n",
    "    \n",
    "    # Dimensions of g4: batch_size x 28 x 28 x 1\n",
    "    return g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Generate sample image using our generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_dimensions = 100\n",
    "z_placeholder = tf.placeholder(dtype=float32, [None, z_dimensions])\n",
    "\n",
    "generated_image_output = generator(z_placeholder, 1, z_dimensions)\n",
    "                        # mean, std, [dimensions]\n",
    "z_batch = np.random.normal(0, 1, [1, z_dimensions])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    generated_image = sess.run(generated_image_output, feed_dict = {z_placeholder: z_batch})\n",
    "    generated_image = generated_image.reshape([28,28])\n",
    "    plt.imshow(generated_image, cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Training the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 50\n",
    "\n",
    "z_placeholder = tf.placeholder(float32, [None, z_dimensions], name = 'z_placeholder')\n",
    "\n",
    "x_placeholder = tf.placeholder(float32, [None, 28, 28, 1], name = 'x_placeholder')\n",
    "\n",
    "Gz = generator(z_placeholder, batch_size, z_dimensions)\n",
    "\n",
    "Dx = discriminator(x_placeholder)\n",
    "\n",
    "Dg = discriminator(Gz, reuse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits= Dz, labels=tf.zeros_like(Dz)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate generator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Trainable weights for generators and discriminators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_trainer_fake = tf.train.AdamOptimizer(0.0003).minimize(d_loss_fake, var_list = d_vars)\n",
    "d_trainer_real = tf.train.AdamOptimizer(0.0003).minimize(d_loss_real, var_list = d_vars)\n",
    "\n",
    "g_trainer = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list = g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "tf.summary.scalar('Generator_loss', g_loss)\n",
    "tf.summary.scalar('Discriminator_loss_real', d_loss_real)\n",
    "tf.summary.scalar('Discriminator loss fake', d_loss_fake)\n",
    "\n",
    "images_for_tensorboard = generator(z_placeholder, batch_size, z_dimensions)\n",
    "tf.summary.image('Generated_images', images_for_tensorboard, 5)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Pretrain discriminator with real images as well as fake noise\n",
    "for i in range(300):\n",
    "    z_batch = np.random.normal(0, 1, size = [None, z_dimensions])\n",
    "    real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "    _, _. dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake], \n",
    "                                          {x_placeholder: real_image_batch, z_placeholder:z_batch})\n",
    "    \n",
    "    if(i % 100 == 0):\n",
    "        print('dLossReal:', dLossReal, 'dLossFake:', dLossFake)\n",
    "        \n",
    "# Train generator and descriminator together\n",
    "\n",
    "for i in range(100000):\n",
    "    real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "    z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "\n",
    "    # Train discriminator on both real and fake images\n",
    "    _, __, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n",
    "                                           {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "    \n",
    "    z_batch = tf.random_normal(0,1, [batch_size, z_dimensions])\n",
    "    _ = sess.run([g_trainer, g_loss], {z_placeholder:z_batch})\n",
    "\n",
    "    if(i % 10 == 0):\n",
    "        # Update Tensorboard with summary statistics\n",
    "        z_batch = tf.random_normal(0,1, [batch_size, z_dimensions])\n",
    "        summary = sess.run(merged, {z_placeholder: z_batch, x_placeholder:real_image_batch})\n",
    "        writer.add_summary(summary, i)\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        # Every 100 iterations, show a generated image\n",
    "        print(\"Iteration:\", i, \"at\", datetime.datetime.now())\n",
    "        z_batch = np.random.normal(0, 1, size=[1, z_dimensions])\n",
    "        generated_images = generator(z_placeholder, 1, z_dimensions)\n",
    "        images = sess.run(generated_images, {z_placeholder: z_batch})\n",
    "        plt.imshow(images[0].reshape([28, 28]), cmap='Greys')\n",
    "        plt.show()\n",
    "\n",
    "        # Show discriminator's estimate\n",
    "        im = images[0].reshape([1, 28, 28, 1])\n",
    "        result = discriminator(x_placeholder)\n",
    "        estimate = sess.run(result, {x_placeholder: im})\n",
    "        print(\"Estimate:\", estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
